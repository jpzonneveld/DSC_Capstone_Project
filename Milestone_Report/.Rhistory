install.packages(AppliedPredictiveModeling)
install.packages('AppliedPredictiveModeling')
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[trainIndex,]
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
str(training)
hist(training$Superplasticizer)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainIL <- training[,grep('^IL', x =names(training))]
prep <- preProcess(trainIL, method ='pca', thresh=0.9, outcome=traing$diagnosis)
str(prep)
prep
prep$rotation
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL <- grep("^IL", colnames(training), value=TRUE)
ILpredictors <- predictors[, IL]
df <- data.frame(diagnosis, ILpredictors)
inTrain <- createDataPartition(df$diagnosis, p=3/4)[[1]]
training <- df[inTrain, ]
testing <- df[-inTrain, ]
modelFit <- train(diagnosis ~ ., method="glm", data=training)
predictions <- predict(modelFit, newdata=testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p=3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
IL <- grep("^IL", colnames(training), value=TRUE)
ILpredictors <- predictors[, IL]
df <- data.frame(diagnosis, ILpredictors)
inTrain <- createDataPartition(df$diagnosis, p=3/4)[[1]]
training <- df[inTrain, ]
testing <- df[-inTrain, ]
modelFit <- train(diagnosis ~ ., method="glm", data=training)
predictions <- predict(modelFit, newdata=testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
acc1 <- C1$overall[1]
acc1 # Non-PCA Accuracy: 0.65
modelFit <- train(training$diagnosis ~ .,
method="glm",
preProcess="pca",
data=training,
trControl=trainControl(preProcOptions=list(thresh=0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit, testing))
print(C2)
acc2 <- C2$overall[1]
acc2 # PCA Accuracy: 0.72
install.packages('caret', dependencies = TRUE)
install.packages("caret", dependencies = TRUE)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p=3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
IL <- grep("^IL", colnames(training), value=TRUE)
ILpredictors <- predictors[, IL]
df <- data.frame(diagnosis, ILpredictors)
inTrain <- createDataPartition(df$diagnosis, p=3/4)[[1]]
training <- df[inTrain, ]
testing <- df[-inTrain, ]
modelFit <- train(diagnosis ~ ., method="glm", data=training)
predictions <- predict(modelFit, newdata=testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
acc1 <- C1$overall[1]
acc1 # Non-PCA Accuracy: 0.65
modelFit <- train(training$diagnosis ~ .,
method="glm",
preProcess="pca",
data=training,
trControl=trainControl(preProcOptions=list(thresh=0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit, testing))
print(C2)
acc2 <- C2$overall[1]
acc2 # PCA Accuracy: 0.72
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
train = createDataPartition(diagnosis, p = 0.50,list=FALSE)
test = createDataPartition(diagnosis, p = 0.50,list=FALSE)
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
?createDataPartition
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
str(training)
hist(concrete$Superplasticizer)
hist(log(concrete$Superplasticizer))
log(0)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
str(training)
grep("IL*", names(training), ignor.case = TRUE)
grep("IL*", names(training))
grep("^IL*", names(training))
?preProcess
training2<-training[grep("^IL*", names(training)),]
preProc <- preProcess(training2, method='pca', thresh=0.8,
outcome=training$diagnosis)
training2<-training[grep("^IL*", names(training)),]
training2<-training[,grep("^IL*", names(training))]
preProc <- preProcess(training2, method='pca', thresh=0.8,
outcome=training$diagnosis)
preProc
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
newadData = adData[,grep("^IL*", names(adData))]
inTrain2 = createDataPartition(newadData$diagnosis, p = 3/4)[[1]]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL <- grep("^IL*", names(training), value = TRUE)
IL
IL <- grep("^IL", names(training), value = TRUE)
IL
ILpredictors <- predictors[,IL]
ILadData = data.frame(diagnosis,ILpredictors)
inTrain = createDataPartition(ILadData$diagnosis, p = 3/4)[[1]]
ILinTrain = createDataPartition(ILadData$diagnosis, p = 3/4)[[1]]
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
ILtraining = ILadData[ILinTrain,]
ILtesting = ILadData[-ILinTrain,]
modelFitGLM <- train(diagnosis ~., data=ILtraining, method="glm")
predictionsGLM <- predict(modelFitGLM, data=ILtesting)
predictionsGLM <- predict(modelFitGLM, newdata=ILtesting)
Conf1 <- confusionMatrix(predictions, testing$diagnosis)
Conf1 <- confusionMatrix(predictionsGLM, testing$diagnosis)
Conf1
modelFitPCA <- train(diagnosis ~., data=ILtraining, method="glm", preProcess = "pca", trControl=trainControl(preProcOptions=list(thresh=0.8)))
predictionsPCA <- predict(modelFitPCA, newdata=ILtesting)
Conf1 <- confusionMatrix(predictionsPCA, testing$diagnosis)
Conf1
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL <- grep("^IL", names(training), Value = TRUE)
IL <- grep("^IL", names(training), value = TRUE)
IL
training2 <- training[IL,]
training2 <- training[,IL]
preProc <- preProcess(training2, method = "pca", thresh = 0.8)
preProc
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=0.75, list =FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
dim(training)
set.seed(125)
modelFit <- train(Case ~ ., data=training, method="rpart")
modelFit
modelFit$finalModel
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
data <- segmentationOriginal
set.seed(125)
inTrain <- data$Case == "Train"
trainData <- data[inTrain, ]
testData <- data[!inTrain, ]
cartModel <- train(Class ~ ., data=trainData, method="rpart")
cartModel$finalModel
plot(cartModel$finalModel, uniform=T)
text(cartModel$finalModel, cex=0.8)
plot(cartModel$finalModel, uniform=T)
> text(cartModel$finalModel, cex=0.8)
text(cartModel$finalModel, cex=0.8)
head(segmentationOriginal$Case)
library(pgmm)
data(olive)
olive = olive[,-1]
download.packages('pgmm')
download.packages("pgmm")
instal.packages("pgmm")
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
model <- train(Area ~ ., data = olive, method ="rpart2")
model
newdata <- as.data.frame(t(colMeans(olive)))
predict(model, newdata)
head(olive)
str(olive)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
str(SAheart)
model <- train(chd ~ age + alcohol + obesity + tabacco + typea + ldl, data = trainSA, method ="glm", family="binomial")
model <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, method ="glm", family="binomial")
logitModel <- train(chd ~ age + alcohol + obesity + tobacco +
typea + ldl, data=trainSA, method="glm",
family="binomial")
logitModel
missClass <- function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
predictTrain <- predict(logitModel, trainSA)
predictTest <- predict(logitModel, testSA)
missClass(trainSA$chd, predictTrain)
missClass(testSA$chd, predictTest)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
head(vowel.train)
head(vowel.test)
dim(vowel.train) # 528  11
dim(vowel.test) # 462  11
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modelRf <- randomForest(y ~., data=vowel.train, importance = FALSE)
install.packages("randomForest")
library(randomForest)
modelRf <- randomForest(y ~., data=vowel.train, importance = FALSE)
order(varImp(modelRf), decreasing=T)
install.packages("AppliedPredictiveModeling")
install.packages("ElemStatLearn")
install.packages("pgmm")
install.packages("gbm")
install.packages("lubridate")
install.packages("forecast")
install.packages("e1071")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(caret)
modelRF <- train(y ~ ., data = vowel.train, method="rf")
modelGBM <- train(y ~ ., data = vowel.train, method="gbm")
predictRF <- predict(modelRF, vowel.test)
predictGBM <- predict(modelGBM, vowel.test)
predictRF
confusionmatrix(predictRF)
confusionMatrix(predictRF)
accuracy(predictRF)
confusionMatrix(predictRF, vowel.test$y)
confusionMatrix(predictGMB, vowel.test$y)
confusionMatrix(predictGB<, vowel.test$y)
confusionMatrix(predictGBM, vowel.test$y)
confusionMatrix(predGBM, vowel.test$y)$overall[1]
confusionMatrix(predictGBM, vowel.test$y)$overall[1]
pred <- data.frame(predRf, predGBM, y=vowel.test$y, agree=predRf == predGBM)
pred <- data.frame(predictRF, predictGBM, y=vowel.test$y, agree=predictRF == predictGBM)
head(pred)
accuarcy <- sum(predictRF[pred$agree] == pred$y[pred$agree]) / sum(pred$agree)
accuracy
accuarcy
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
fitRf <- train(diagnosis~., data = training, method="rf")
fitGBM <- train(diagnosis ~ ., data=training, method="gbm")
fitLDA <- train(diagnosis ~ ., data=training, method="lda")
predRf <- predict(fitRf, testing)
predGBM <- predict(fitGBM, testing)
predLDA <- predict(fitLDA, testing)
pred <- data.fram(predRf, predGBM, predLDA, diagnosis=testing$diagnosis)
pred <- data.frame(predRf, predGBM, predLDA, diagnosis=testing$diagnosis)
fit <- train(diagnosis ~., data=pred, method="rf")
predFit <- predict(fit, testing)
c1 <- confusionMatrix(predRf, testing$diagnosis)$overall[1]
c2 <- confusionMatrix(predGBM, testing$diagnosis)$overall[1]
c3 <- confusionMatrix(predLDA, testing$diagnosis)$overall[1]
c4 <- confusionMatrix(predFit, testing$diagnosis)$overall[1]
print(paste(c1, c2, c3, c4))
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData <- data.frame(diagnosis, predictors)
inTrain <- createDataPartition(adData$diagnosis, p=3/4)[[1]]
training <- adData[inTrain, ]
testing <- adData[-inTrain, ]
dim(adData) # 333 131
# head(adData)
set.seed(62433)
fitRf <- train(diagnosis ~ ., data=training, method="rf")
fitGBM <- train(diagnosis ~ ., data=training, method="gbm")
fitLDA <- train(diagnosis ~ ., data=training, method="lda")
predRf <- predict(fitRf, testing)
predGBM <- predict(fitGBM, testing)
predLDA <- predict(fitLDA, testing)
pred <- data.frame(predRf, predGBM, predLDA, diagnosis=testing$diagnosis)
# Stack the predictions together using random forests ("rf")
fit <- train(diagnosis ~., data=pred, method="rf")
predFit <- predict(fit, testing)
c1 <- confusionMatrix(predRf, testing$diagnosis)$overall[1]
c2 <- confusionMatrix(predGBM, testing$diagnosis)$overall[1]
c3 <- confusionMatrix(predLDA, testing$diagnosis)$overall[1]
c4 <- confusionMatrix(predFit, testing$diagnosis)$overall[1]
print(paste(c1, c2, c3, c4))
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
fit <- train(CompressiveStrength ~ ., data=training, method="lasso")
fit
plot.enet(fit$finalModel, xvar="penalty", use.color=T)
library(lubridate)  # For year() function below
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
?bats
model <- bats(training)
model <- bats(tstrain)
model
pred <- forecast(model, level=95, h=dim(testing)[1])
names(data.frame(pred))
predComb <- cbind(testing, data.frame(pred))
names(testing)
names(predComb)
predComb$in95 <- (predComb$Lo.95 < predComb$visitsTumblr) &
(predComb$visitsTumblr < predComb$Hi.95)
prop.table(table(predComb$in95))[2] # 0.9617021
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(e1071)
fit <- svm(CompressiveStrength ~., data=training)
pred <- predict(fit, testing)
acc <- accuracy(pred, testing$CompressiveStrength)
acc
install.packages('slidify')
install.packages("installr"); require(installr)
updateR()
updateR(F, T, T, F, T, F, T)
updateR(F, T, T, F, T, F, T)
update.packages(ask=F)
installed.packages()
installed.packages()[,1:4]
.Library
installed.packages()[,c(1,4)]
library(ggplot2)
library(ggplot2)
update.packages(ask=F)
install.packages('strigi')
library(ggplot2)
install.packages('ggplot2')
library(ggplot2)
blogs <- readLines("../Data/final/en_US/en_US.blogs.txt", encoding ="UTF-8", skipNul = TRUE)
news <- readLines("../Data/final/en_US/en_US.news.txt", encoding ="UTF-8", skipNul = TRUE)
twitter <- readLines("../Data/final/en_US/en_US.twitter.txt", encoding ="UTF-8", skipNul = TRUE)
setwd("~/01 - EMC/01 - Development/01 - Training/2014 Coursera Data Science Track/10 Capstone project/DSC_Capstone_Project/Milestone_Report")
news <- readLines("../Data/final/en_US/en_US.news.txt", encoding ="UTF-8", skipNul = TRUE)
library(tm)
library(slam)
######################################################################################
## Data cleaning function which creates a cleaned corpus
CleanCorpus <- function(InputSource, profanitylist) {
clean_text <- VCorpus(VectorSource(InputSource))
clean_text <- tm_map(clean_text, content_transformer(function(x)
iconv(x, to="ASCII", sub = "byte")))
DeleteSymbol<- function(x) gsub("<..>", " ", x)
clean_text <- tm_map(clean_text, content_transformer(DeleteSymbol))
clean_text <- tm_map(clean_text, content_transformer(function(x)
iconv(x, to="UTF-8", sub = "byte")))
clean_text <- tm_map(clean_text, stripWhitespace)
clean_text <- tm_map(clean_text, content_transformer(tolower))
#      clean_text <- tm_map(clean_text, removeWords, stopwords("english"))
clean_text <- tm_map(clean_text, removeWords, profanity)
clean_text <- tm_map(clean_text, content_transformer(removePunctuation))
clean_text <- tm_map(clean_text, content_transformer(removeNumbers))
clean_text <- tm_map(clean_text, stripWhitespace)
#      clean_text <- tm_map(clean_text, stemDocument)
clean_text
}
## Creates a DF based on the input corpus.
CorpustoDF <- function(InputSource){
data.frame(text=unlist(sapply(InputSource,`[`, "content")),
stringsAsFactors = FALSE)
}
## Word Frequency DF function, creates a data frame with the frequency
## for a corpus.
WordFrequencyDF <- function(InputSource) {
tdm <- TermDocumentMatrix(InputSource)
freq <- sort(row_sums(tdm, na.rm=TRUE), decreasing=TRUE)
word <- names(freq)
data.frame(word=word, freq=freq)
}
#####################################################################################
## Load profanity word list
## source: https://gist.github.com/jamiew/1112488
profanity <- readLines("../Data/profanityfilter.txt")
news_corpus <- CleanCorpus(news, profanity)
writeLines(as.character(news_corpus), con="../Data/en_US.news.clean.txt")
newsDF <- CorpustoDF(news_corpus)
writeLines(as.character(newsDF), con="../Data/en_US.news.clean.txt")
news_try <_ readLines(con = "../Data/en_US.news.clean.txt")
news_try <- readLines(con = "../Data/en_US.news.clean.txt")
head(news_try)
writeLines(newsDF, con="../Data/en_US.news.clean.txt")
?write.table
write.table(newsDF, file = "../Data/en_US.news.clean.txt")
View(newsDF)
View(newsDF)
write.table(newsDF, file = "../Data/en_US.news.clean.txt", row.names = FALSE, col.names = FALSE)
write.table(newsDF, file = "../Data/en_US.news.clean.txt", row.names = FALSE, col.names = FALSE, quote=FALSE)
news <- readLines("../Data/en_US.news.clean.txt", encoding ="UTF-8", skipNul = TRUE)
head(news)
